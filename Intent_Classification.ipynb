{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VSubhash1/Intent-Classification-/blob/main/Intent_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HgvNjYfI288t"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch sentencepiece speechrecognition pyaudio gTTS gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_LI9mY684WHF"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y portaudio19-dev\n",
        "!pip install pyaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FvhJqOyZ5P_k"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch sentencepiece gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-jSWyrm5Uyl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gradio as gr\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wYg31LP5aG8"
      },
      "outputs": [],
      "source": [
        "intents = {\n",
        "    \"intents\": [\n",
        "        {\"tag\": \"greeting\",\n",
        "         \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"Good morning\", \"Good evening\"],\n",
        "         \"responses\": [\"Hello!\", \"Hi there!\", \"Hey!\"]},\n",
        "\n",
        "        {\"tag\": \"goodbye\",\n",
        "         \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"See ya\"],\n",
        "         \"responses\": [\"Goodbye!\", \"Take care!\", \"See you!\"]},\n",
        "\n",
        "        {\"tag\": \"thanks\",\n",
        "         \"patterns\": [\"Thanks\", \"Thank you\", \"Much appreciated\"],\n",
        "         \"responses\": [\"You're welcome!\", \"No problem!\", \"Glad to help!\"]},\n",
        "\n",
        "        {\"tag\": \"order_pizza\",\n",
        "         \"patterns\": [\"I want a pizza\", \"Can I order pizza?\", \"Pizza delivery\"],\n",
        "         \"responses\": [\"Sure! What toppings?\", \"Ordering pizza now!\"]}\n",
        "    ]\n",
        "}\n",
        "\n",
        "sentences, labels, label2id, id2label = [], [], {}, {}\n",
        "for i, intent in enumerate(intents[\"intents\"]):\n",
        "    tag = intent[\"tag\"]\n",
        "    label2id[tag] = i\n",
        "    id2label[i] = tag\n",
        "    for p in intent[\"patterns\"]:\n",
        "        sentences.append(p)\n",
        "        labels.append(i)\n",
        "\n",
        "print(\"Classes:\", label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTS7GzW-5_5W"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "class IntentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=32):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=\"max_length\",\n",
        "                                  max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return { \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "                 \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "                 \"labels\": torch.tensor(label) }\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
        "train_dataset = IntentDataset(X_train, y_train, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju7rFfzQ6SmY"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label2id))\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "for epoch in range(2):  # demo training\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpTCvfPa6hSV"
      },
      "outputs": [],
      "source": [
        "def predict_intent(text):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)\n",
        "    pred_label = torch.argmax(probs, dim=1).item()\n",
        "    return id2label[pred_label], float(probs[0][pred_label])\n",
        "\n",
        "def classify_intent(user_input):\n",
        "    intent, conf = predict_intent(user_input)\n",
        "    return f\"Predicted intent: {intent}\\nConfidence: {conf:.2f}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def voice_to_text(file_path):\n",
        "    import speech_recognition as sr\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "    text = recognizer.recognize_google(audio)\n",
        "    intent, conf = predict_intent(text)\n",
        "    return f\"You said: {text}\\nPredicted intent: {intent}\\nConfidence: {conf:.2f}\""
      ],
      "metadata": {
        "id": "jVtYWS37wYOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tts_response(user_input):\n",
        "    from gtts import gTTS\n",
        "    intent, conf = predict_intent(user_input)\n",
        "    response_text = f\"Predicted intent is {intent} with confidence {conf:.2f}\"\n",
        "    tts = gTTS(response_text)\n",
        "    filename = \"response.mp3\"\n",
        "    tts.save(filename)\n",
        "    return filename"
      ],
      "metadata": {
        "id": "WQfAO4wowbgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "Gcdc9dxQ6o5Q",
        "outputId": "a619d5ce-2a93-4fc7-b8ca-f99a52cc7b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0cd94310082f9af0a7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0cd94310082f9af0a7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ðŸŽ¤ Intent Classifier with BERT (Text + Voice)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        text_in = gr.Textbox(label=\"Type your message\")\n",
        "        text_out = gr.Textbox(label=\"Predicted Intent\")\n",
        "    btn1 = gr.Button(\"Classify Text\")\n",
        "    btn1.click(classify_intent, inputs=text_in, outputs=text_out)\n",
        "\n",
        "    gr.Markdown(\"Or speak your message ðŸ‘‡\")\n",
        "    mic_in = gr.Audio(type=\"filepath\", label=\"ðŸŽ¤ Speak or Upload Audio\")\n",
        "    voice_out = gr.Textbox(label=\"Predicted Intent (from Voice)\")\n",
        "    btn2 = gr.Button(\"Classify Voice\")\n",
        "    btn2.click(voice_to_text, inputs=mic_in, outputs=voice_out)\n",
        "\n",
        "    gr.Markdown(\"ðŸ”Š Get spoken response\")\n",
        "    tts_in = gr.Textbox(label=\"Type message for spoken prediction\")\n",
        "    tts_out = gr.Audio(label=\"Voice Output\")\n",
        "    btn3 = gr.Button(\"Speak Prediction\")\n",
        "    btn3.click(tts_response, inputs=tts_in, outputs=tts_out)\n",
        "\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WfRi98qNAhXd"
      },
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}